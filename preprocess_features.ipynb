{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import f1_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Данные"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- app_id - Идентификатор заявки.\n",
    "- amnt - Нормированная сумма транзакции\n",
    "- currency - Идентификатор валюты транзакции\n",
    "- operation_kind - Идентификатор типа транзакции\n",
    "- card_type - Уникальный идентификатор типа карты\n",
    "- operation_type - Идентификатор типа операции по пластиковой карте\n",
    "- operation_type_group - Идентификатор группы карточных операций (дебетовая карта, кредитная карта)\n",
    "- ecommerce_flag - Признак электронной коммерции\n",
    "- payment_system - Идентификатор типа платежной системы\n",
    "- income_flag - Признак списания/внесения денежных средств на карту\n",
    "- mcc - Уникальный идентификатор типа торговой точки\n",
    "- country - Идентификатор страны транзакции\n",
    "- city - Идентификатор города транзакции\n",
    "- mcc_category - Идентификатор категории магазина транзакции\n",
    "- day_of_week - День недели, когда транзакция была совершена\n",
    "- hour - Час, когда транзакция была совершена\n",
    "- days_before - Количество дней до даты выдачи кредита\n",
    "- weekofyear - Номер недели в году, когда транзакция была совершена\n",
    "- hour_diff - Количество часов с момента прошлой транзакции для данного клиента\n",
    "- transaction_number - Порядковый номер транзакции клиента"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сгенерированные признаки:\n",
    "- Основые статистики для числовых признаков: min, max, std, mean, 25%, 50%, 75%\n",
    "- Мода и количество уникальных значений для категориальных\n",
    "- Счетчики для значений категориальных переменных\n",
    "- Сумма amount отдельно для списаний и зачислений\n",
    "- Все признаки выше для последних 20% транзакций\n",
    "- Последние значения для всех признаков\n",
    "- Отношение первого значения amount к последнему "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = ['amnt', 'day_of_week', 'hour', 'days_before', 'weekofyear', 'hour_diff']\n",
    "cat_features = ['currency', 'operation_kind', 'card_type', 'operation_type', 'operation_type_group', \n",
    "                'ecommerce_flag', 'payment_system', 'income_flag', 'mcc', 'country', 'city', 'mcc_category']\n",
    "\n",
    "def get_mode(series):\n",
    "    return series.mode().iloc[0] if not series.mode().empty else None\n",
    "\n",
    "def aggregate_features(data):\n",
    "    n_transactions = data.groupby(['app_id'])['transaction_number'].count().to_frame(name='n_transactions')\n",
    "    num_stat = data.groupby('app_id')[num_features].agg('describe')\n",
    "    num_stat.columns = num_stat.columns.map(' '.join)\n",
    "    cat_agg = data.groupby('app_id')[cat_features].agg(['nunique', get_mode])\n",
    "    cat_agg.columns = cat_agg.columns.map(' '.join)\n",
    "    cat_counts = []\n",
    "    for feature in cat_features:\n",
    "        cat_count = data.groupby(['app_id', feature])['transaction_number'].count().unstack(fill_value=0)\n",
    "        cat_count.columns = [' '.join([feature, str(col)]) for col in cat_count.columns]\n",
    "        cat_counts.append(cat_count)\n",
    "    cat_counts = pd.concat(cat_counts, axis=1)\n",
    "    amnt_type = data.groupby(['app_id', 'income_flag'])['amnt'].sum().unstack()\n",
    "    amnt_type.columns = [' '.join(['amnt type', str(col)]) for col in amnt_type.columns]\n",
    "    \n",
    "    return pd.concat([n_transactions, num_stat, cat_agg, cat_counts, amnt_type], axis=1)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_file(dir, filename):\n",
    "    data = pd.read_parquet(os.path.join(dir, filename))\n",
    "    main_features = aggregate_features(data)\n",
    "    last_data = data.groupby(['app_id']).apply(lambda x: x.tail(round(0.2 *(len(x)))))\n",
    "    last_features = aggregate_features(last_data.reset_index(drop=True))\n",
    "    abs_in_last = list(set(main_features.columns) - set(last_features.columns))\n",
    "    last_features[abs_in_last] = 0\n",
    "    last_features.columns = 'last period ' + last_features.columns\n",
    "\n",
    "    last_values = data.groupby(['app_id']).agg('last')\n",
    "    last_values.columns = 'last ' + last_values.columns\n",
    "\n",
    "    amnt = data.groupby(['app_id'])['amnt'].agg(['first', 'last'])\n",
    "    amnt_first_last = (amnt['first'] / amnt['last']).to_frame(name='amnt_first_last')\n",
    "\n",
    "    fin_data = pd.concat([main_features, last_features, last_values, amnt_first_last], axis=1)\n",
    "    return fin_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirname = '../default/train_transactions_contest'\n",
    "all_data = []\n",
    "for filename in os.listdir(dirname):\n",
    "    all_data.append(process_file(dirname, filename))\n",
    "train_data = pd.concat(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.drop('app_id', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = pd.read_csv('train_target.csv')\n",
    "train_data = train_data.merge(target, on='app_id')\n",
    "train_data = train_data.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Возьмем 0 и 1 класс в равных пропорциях, чтобы избежать дисбаланса классов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_0 = train_data[train_data['flag'] == 0]\n",
    "train_1 = train_data[train_data['flag'] == 1]\n",
    "sample0 = train_0.sample(n=26577, random_state=42).reset_index()\n",
    "sample1 = train_1.sample(n=26577, random_state=42).reset_index()\n",
    "train_sample = pd.concat([sample0, sample1])\n",
    "train_sample = train_sample.sample(frac=1).reset_index(drop=True)\n",
    "train_sample = train_sample.drop(['index'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Удалим константные признаки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sample = pd.read_csv('data/train_sample.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "constant_cols = train_sample.columns[train_sample.nunique() <= 1]\n",
    "train_sample = train_sample.drop(constant_cols, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И сильно скореллированные признаки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_data = train_sample['flag']\n",
    "X_data = train_sample.drop('flag', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlations = defaultdict(list)\n",
    "corr_mat = X_data.corr().values.tolist()\n",
    "columns = X_data.columns\n",
    "for ind_r, row in enumerate(corr_mat):\n",
    "    for ind_c, col in enumerate(row):\n",
    "        if ind_r != ind_c and corr_mat[ind_r][ind_c] > 0.95:\n",
    "            correlations[columns[ind_r]].append(columns[ind_c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_drop = []\n",
    "for feature, group in correlations.items():\n",
    "    if feature not in features_to_drop:\n",
    "        for feature2 in group:\n",
    "            features_to_drop.append(feature2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data = X_data.drop(features_to_drop, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Select from model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, X_test, y, y_test = train_test_split(X_data, y_data, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_splits = 5\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_scores = []\n",
    "all_models = []\n",
    "for i, (train_ind, val_ind) in enumerate(skf.split(X.values, y)):\n",
    "    X_train, X_val = X.iloc[train_ind, :], X.iloc[val_ind, :]\n",
    "    y_train, y_val = y.iloc[train_ind], y.iloc[val_ind]\n",
    "    lgb_model = CatBoostClassifier(verbose=0, random_state=42)\n",
    "    all_models.append(lgb_model)\n",
    "    lgb_model.fit(X_train, y_train)\n",
    "    val_preds = lgb_model.predict(X_val)\n",
    "    f1 = f1_score(val_preds, y_val)\n",
    "    f1_scores.append(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = np.zeros(len(X.columns))\n",
    "for model in all_models:\n",
    "    importances += model.feature_importances_ / len(all_models)\n",
    "importances = list(zip(X.columns, importances))\n",
    "importances.sort(key=lambda x: x[1], reverse=True)\n",
    "features_to_select = [feature for feature, imp in importances[:600]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Топ признаков:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hour_diff 50%',\n",
       " 'hour std',\n",
       " 'product',\n",
       " 'hour_diff 75%',\n",
       " 'hour_diff max',\n",
       " 'amnt 25%',\n",
       " 'mcc_category 9',\n",
       " 'operation_kind 2',\n",
       " 'operation_type 5',\n",
       " 'days_before max',\n",
       " 'last period hour_diff 50%',\n",
       " 'amnt max',\n",
       " 'mcc 36',\n",
       " 'mcc nunique',\n",
       " 'mcc_category 10',\n",
       " 'mcc 33',\n",
       " 'mcc_category nunique',\n",
       " 'amnt 75%',\n",
       " 'amnt mean',\n",
       " 'hour max']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_to_select[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data = X_data[features_to_select]\n",
    "train_sample = pd.concat([X_data, y_data], axis=1)\n",
    "train_sample.to_csv('train_sample.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
